{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spaceship Titanic has begun\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(r'C:\\Users\\omarf\\Downloads\\spaceship-titanic\\train.csv')\n",
    "df_test = pd.read_csv(r'C:\\Users\\omarf\\Downloads\\spaceship-titanic\\test.csv')  \n",
    "df_test['Transported'] = False\n",
    "\n",
    "df = pd.concat([df_train, df_test], sort = False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: Loading your dataset (replace 'your_dataset.csv' with your actual file)\n",
    "df = pd.read_csv(r'C:\\Users\\omarf\\Downloads\\spaceship-titanic\\train.csv')\n",
    "\n",
    "# Step 1: Check if 'CryoSleep' column exists\n",
    "if 'CryoSleep' in df.columns:\n",
    "    print(\"CryoSleep column found!\")\n",
    "\n",
    "    # Step 2: Handle missing values and normalize data\n",
    "    # Convert all values to booleans or None (if they are not already)\n",
    "    df['CryoSleep'] = df['CryoSleep'].astype(str).str.strip().str.lower()  # Normalize to lowercase strings\n",
    "    df['CryoSleep'] = df['CryoSleep'].map({'true': True, 'false': False, 'nan': None})  # Map to boolean\n",
    "\n",
    "    # Optional: Fill missing values with False (or keep as None, depending on your requirements)\n",
    "    df['CryoSleep'].fillna(False, inplace=True)\n",
    "\n",
    "    # Step 3: Check unique values to verify cleanup\n",
    "    print(\"Unique values in 'CryoSleep':\", df['CryoSleep'].unique())\n",
    "\n",
    "    # Example usage: Filter rows where CryoSleep is True\n",
    "    cryosleep_passengers = df[df['CryoSleep'] == True]\n",
    "    print(f\"Number of passengers in CryoSleep: {len(cryosleep_passengers)}\")\n",
    "\n",
    "else:\n",
    "    print(\"CryoSleep column not found in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0] == df_train.shape[0] + df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Deck','Num','Side']] = df['Cabin'].str.split('/', expand=True)\n",
    "columns_to_drop = ['Name', 'Cryosleep']\n",
    "df.drop(columns=[col for col in columns_to_drop if col in df.columns], axis=1, inplace=True)\n",
    "df['Deck'] = df['Deck'].fillna('U')\n",
    "df['Side'] = df['Side'].fillna('U')\n",
    "df['Num'] = df['Num'].fillna(-1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Deck'] = df['Deck'].map({'G':0, 'F':1, 'E':2, 'D':3, 'C':4, 'B':5, 'A':6, 'U':7, 'T':8})\n",
    "df['Side'] = df['Side'].map({'U':-1, 'P':1, 'S':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_list = ['Age','Num','Side','CryoSleep','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck','Deck','VIP']\n",
    "rest = list(set(df.columns) - set(impute_list))\n",
    "df_rest = df[rest]\n",
    "imp = KNNImputer()\n",
    "df_imputed = imp.fit_transform(df[impute_list])\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=impute_list)\n",
    "df = pd.concat([df_rest.reset_index(drop=True), df_imputed.reset_index(drop=True)], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HomePlanet'] = df['HomePlanet'].fillna('U')\n",
    "df['Destination'] = df['Destination'].fillna('U')\n",
    "df['Cabin'] = df['Cabin'].fillna('U')\n",
    "\n",
    "category_colls = ['HomePlanet','Destination']\n",
    "\n",
    "for col in category_colls:\n",
    "   df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\n",
    "df.drop(columns=category_colls, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "bill_cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "df['amt_spent'] = df[bill_cols].sum(axis=1)\n",
    "df['std_amt_spent'] = df[bill_cols].std(axis=1)\n",
    "df['mean_amt_spent'] = df[bill_cols].mean(axis=1)\n",
    "\n",
    "df['3_High_colls'] = df['CryoSleep'] + df['HomePlanet_Europa'] + df['Destination_55 Cancri e']\n",
    "df['3_low_colls'] = df['amt_spent'] + df['mean_amt_spent'] + df['HomePlanet_Earth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Transported' column is included in numeric_df\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "numeric_df['Transported'] = df['Transported'].astype(float)\n",
    "numeric_df.corr()['Transported'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df[:df_train.shape[0]], df[df_train.shape[0]:]\n",
    "df_test = df_test.drop('Transported', axis=1)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns = 'Transported')\n",
    "y = df_train['Transported']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "model_1 = LogisticRegression()\n",
    "model_2 = DecisionTreeClassifier()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_4 = XGBRFClassifier()\n",
    "model_5 = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all features are numeric\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(-1)\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(-1)\n",
    "\n",
    "model_1.fit(X_train, y_train)\n",
    "pred = model_1.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(X_train, y_train)\n",
    "pred = model_2.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train, y_train)\n",
    "pred = model_3.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.fit(X_train, y_train)\n",
    "pred = model_4.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.fit(X_train, y_train)\n",
    "pred = model_5.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predictions DataFrame\n",
    "\n",
    "df_dummy = pd.read_csv(r'C:\\Users\\omarf\\Downloads\\spaceship-titanic\\test.csv')\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final['PassengerId'] = df_dummy['PassengerId']  # Ensure all 4,277 PassengerIds are included\n",
    "final['Transported'] = False  # Default value for missing predictions\n",
    "\n",
    "# Ensure 'PassengerId' is present in X_test\n",
    "X_test['PassengerId'] = df.loc[X_test.index, 'PassengerId']\n",
    "\n",
    "# Match predictions to the Passenger IDs in the full dataset\n",
    "predictions_df = pd.DataFrame({'PassengerId': X_test['PassengerId'], 'Transported': pred})\n",
    "final = final.merge(predictions_df, on='PassengerId', how='left')\n",
    "\n",
    "# Fill missing predictions with default value (e.g., False)\n",
    "final['Transported'] = final['Transported_y'].fillna(False).astype(bool)\n",
    "\n",
    "# Save the final output with 4,277 rows\n",
    "final.to_csv(r'C:\\Users\\omarf\\Downloads\\Submission_csv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predictions back into the original test dataset\n",
    "final = df_dummy[['PassengerId']].merge(predictions_df, on='PassengerId', how='left')\n",
    "\n",
    "# After the merge, ensure only one 'Transported' column exists\n",
    "final = final[['PassengerId', 'Transported']]  # Keep only these two columns\n",
    "\n",
    "# Fill missing predictions with a default value (e.g., False)\n",
    "final['Transported'] = final['Transported'].fillna(False).astype(bool)\n",
    "\n",
    "# Save the final output\n",
    "final.to_csv(r'C:\\Users\\omarf\\Downloads\\Submission_csv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
